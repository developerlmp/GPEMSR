#### general settings
name: EMSR_v1_x16_bestref
scale: 16
use_tb_logger: true
use_gpu: true
dist: true
save_checkpoint_freq: !!float 5e3
stage: 3
path:
  root: ~

#### datasets
datasets:
  train:
    name: CREMIDataset
    mode: train
    interval_list: [1]
    random_reverse: false
    border_mode: false
    dataroot_GT: /data/shoujt/CREMI/CREMI/train/HR/x2
    dataroot_LQ: /data/shoujt/CREMI/CREMI/train/LR/x16_direct
    data_type: 'img'
    N_frames: 5
    use_shuffle: true
    n_workers: 16  # per GPU
    batch_size: 4
    GT_size: 256
    LQ_size: 16
    use_flip: true
    use_rot: true

  val:
    name: CREMIDataset
    mode: val
    dataroot_GT: /data/shoujt/CREMI/CREMI/test/HR/x2
    dataroot_LQ: /data/shoujt/CREMI/CREMI/test/LR/x16_direct
    interval_list: [1]
    random_reverse: false
    border_mode: false
    cache_data: True
    N_frames: 5
    padding: new_info

#### network structures
network:
  ref_path_G: /data/shoujt/VQGAN/experiments/VQGAN_Codebook_v4_woLPIPS_v1024_f32/models/generator/430000_G.pth
  ref_path_lrEncoder: /data/shoujt/VQGAN/experiments/VQGAN_Encoder_v3_x16/models/lrencoder16/265000_G.pth # best
  nf: 64
  nframes: 5
  groups: 8
  front_RBs: 5
  back_RBs: 10
  w_ref: True
  ref_fusion_feat_RBs: 1
  align_mode: 'PCD'
  align_atten: false
  fusion_mode: 'TSA'
  mode: '16to1'
  argref:
    lrEncoder16:
      channel_list: [ 64,64,64,128,256,512 ]
      im_channel: 1
      num_resblock_per_scale: 2
      num_output_resblck: 3
      latent_dim: 512
      use_non_local: true
    Encoder:
      channel_list: [64,64,64,128,256,512]
      im_channel: 1
      num_resblock_per_scale: 1
      num_output_resblck: 3
      latent_dim: 512
      use_non_local: true
    Codebook:
      num_codebook_vectors: 1024
      latent_dim: 512
      beta: 1 #loss权重
    Decoder:
      channel_list: [512,256,128,64,64,64]
      im_channel: 1
      num_resblock_per_scale: 1
      num_input_resblck: 3
      latent_dim: 512
      use_non_local: true


#### pretrain
pretrain:
  EMSR: ~
  strict_load: true #lrencoder
  training_state: ~

#### training settings: learning rate scheme, loss
train:
  current_step: 0
  start_epoch: 0
  lr_G: !!float 4e-4
  lr_scheme: CosineAnnealingLR_Restart
  beta1: 0.9
  beta2: 0.99
  niter: 480000
  T_period: [40000, 80000, 120000, 120000, 120000]
  restarts: [40000, 120000, 240000, 360000]
  restart_weights: [1, 1, 1, 1]
  eta_min: !!float 1e-7
  val_freq: !!float 5e3
  manual_seed: 0
  rec_loss_factor: 1
  ref_loss_factor: 0.01
  logger_freq: 100

val:
  val_freq: !!float 5e3
  val_path_version: EMSR_v1_x16_bestref
