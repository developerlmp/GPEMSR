#### general settings
name: VQGAN_Stage1
use_tb_logger: true
use_gpu: true
dist: true
save_checkpoint_freq: !!float 5e3
stage: 1
path:
  root: ~

#### datasets
datasets:
  train:
    name: VQGAN_train
    mode: train
    chooseGTtxt: /GPEMSR-CREMI/GPEMSR/data/train_vqgan.txt
    random_reverse: false
    border_mode: false
    dataroot_GT: /GPEMSR-CREMI/GPEMSR/dataset/stage1_2_data/HR/x16
    use_shuffle: true
    n_workers: 8  # per GPU
    batch_size: 8
    GT_size: 512
    use_flip: true
    use_rot: true
  val:
    name: VQGAN_val
    mode: val
    chooseGTtxt: /GPEMSR-CREMI/GPEMSR/data/val_vqgan.txt
    dataroot_GT: /GPEMSR-CREMI/GPEMSR/dataset/CREMI/test/LR/x16

#### network structures
network:
  Generator:
    Encoder:
      channel_list: [64,64,128,256,512]
      im_channel: 1
      num_resblock_per_scale: 1
      num_output_resblck: 3
      latent_dim: 512
      use_non_local: true
    Codebook:
      num_codebook_vectors: 1024
      latent_dim: 512
      beta: 1
    Decoder:
      channel_list: [512,256,128,64,64]
      im_channel: 1
      num_resblock_per_scale: 1
      num_input_resblck: 3
      latent_dim: 512
      use_non_local: true
  Discriminator:
    im_channel: 1
    num_filters_last: 64
    n_layers: 3

#### pretrain
pretrain:
  pretrain_model_G: ~
  pretrain_model_D: ~
  strict_load: true

#### training settings: learning rate scheme, loss
train:
  current_step: 0
  start_epoch: 0
  lr_G: !!float 4e-4
  lr_D: !!float 4e-4
  lr_scheme: CosineAnnealingLR_Restart
  beta1: 0.9
  beta2: 0.99
  niter: 480000
  T_period: [40000, 80000, 120000, 120000, 120000]
  restarts: [40000, 120000, 240000, 360000]
  restart_weights: [1, 1, 1, 1]
  eta_min: !!float 1e-7
  val_freq: !!float 5e3
  manual_seed: 0
  gan_start: 40000
  gan_loss_factor: 0.05
  rec_loss_factor: 1
  codebook_loss_factor: 10
  perceputual_loss_factor: 0
  logger_freq: 200
  generator_update_rate: 1
  r1_reg_weight: 0.0001
  net_d_reg_every: 16

val:
  val_freq: !!float 5e3
  val_path_version: VQGAN_Stage1
